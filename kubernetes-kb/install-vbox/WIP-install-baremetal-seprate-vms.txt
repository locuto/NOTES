========================================
KUBERNETES INSTALL ON VMS (not as pods)
========================================
https://devops.profitbricks.com/tutorials/deploy-a-multi-node-kubernetes-cluster-on-centos-7/ (seems very good)
- for multinode etcd (this has correct ip settings) - https://coreos.com/etcd/docs/latest/op-guide/clustering.html
- also for multi-node etcd (this has incorrect local ip settings) - http://www.alexlinux.com/etcd-installation-on-centos-7/

https://severalnines.com/blog/installing-kubernetes-cluster-minions-centos7-manage-pods-services  (without certs)
http://www.tothenew.com/blog/how-to-install-kubernetes-on-centos/ (with certs)
https://www.devtech101.com/2018/08/13/installing-a-kubernetes-1-11-cluster-on-centos-7-51804-the-manual-way-installing-3-master-nodes-etcd-part-1/  (complex)

ETCD:
http://www.alexlinux.com/etcd-installation-on-centos-7/

https://coreos.com/etcd/docs/latest/dev-guide/local_cluster.html
https://coreos.com/etcd/docs/latest/op-guide/clustering.html --> also use for certificate, key and tls
https://coreos.com/etcd/docs/latest/getting-started-with-etcd.html

TBD
etcd key, cert, token

ETCDCTL ADD/MODIFY/LIST DATA
https://www.digitalocean.com/community/tutorials/how-to-use-etcdctl-and-etcd-coreos-s-distributed-key-value-store

====================
COMPONENTS
====================
Kubernetes has several components:

etcd - A highly available key-value store for shared configuration and service discovery.
flannel/calico - An etcd backed network fabric for containers.
kube-apiserver - Provides the API for Kubernetes orchestration.
kube-controller-manager - Enforces Kubernetes services.
kube-scheduler - Schedules containers on hosts.
kubelet - Processes a container manifest so the containers are launched according to how they are described.
kube-proxy - Provides network proxy services.

====================
NODE IPs
====================
ke1 - for etcd1
172.168.2.101 - public  - enps08 - host only adapter
192.168.2.101 - private - enps09 - intnet adapter

ke2 - for etcd2
172.168.2.102 - public  - enps08 - host only adapter
192.168.2.103 - private - enps09 - intnet adapter

km1 - for master1
172.168.2.201 - public  - enps08 - host only adapter
192.168.2.201 - private - enps09 - intnet adapter

km2 - for master2
172.168.2.202 - public  - enps08 - host only adapter
192.168.2.202 - private - enps09 - intnet adapter

kw1 - for worker1
172.168.2.251 - public  - enps08 - host only adapter
192.168.2.251 - private - enps09 - intnet adapter

kw2 - for worker2
172.168.2.252 - public  - enps08 - host only adapter
192.168.2.252 - private - enps09 - intnet adapter

==============================
INSTALL AND CONFIGURE
==============================

====================
COMMON STEPS
====================

------------------------------
ADD YUM REPO
------------------------------
# vi /etc/yum.repos.d/virt7-docker-common-release.repo

[virt7-docker-common-release]
name=virt7-docker-common-release
baseurl=http://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/
gpgcheck=0

------------------------------
TURN SWAP OFF
------------------------------
# swapoff -a
# vi /etc/fstab
--> comment out the swap line

---------------------------------
ENABLE br_netfilter
---------------------------------
# modprobe br_netfilter
# echo '1' > /proc/sys/net/bridge/bridge-nf-call-iptables

Also, put it in /etc/sysctl.conf as follows:
net.bridge.bridge-nf-call-iptables = 1

And, make it persistent:
# sysctl -p

====================
ETCD INSTALL
====================
------------------------------
ETCD INSTALL (ON MASTER IF USING SAME FOR MASTER ALSO)
------------------------------

# yum -y install --enablerepo=virt7-docker-common-release etcd

# rpm -qa|grep etcd
etcd-2.0.9-1.el7.x86_64

- SINGLE NODE CONFIGURATION
- /etc/etcd/etcd.conf
[member]
ETCD_NAME=etcd1 --> etcd1, 2 etc for each node
ETCD_DATA_DIR="/var/lib/etcd/default.etcd"  --> leave this as default.etcd --> dont use etcd1 etcd2...
ETCD_LISTEN_CLIENT_URLS="http://192.168.2.101:2379,http://localhost:2379"

[cluster]
ETCD_INITIAL_ADVERTISE_PEER_URLS="http://192.168.2.101:2380"
ETCD_INITIAL_CLUSTER="etcd1=http://192.168.2.101:2380"
ETCD_INITIAL_CLUSTER_STATE="new"
ETCD_ADVERTISE_CLIENT_URLS="http://192.168.2.101:2379"

- MULTI NODE CONFIGURATION
NODE1:
- /etc/etcd/etcd.conf
[member]
ETCD_NAME=etcd1 --> etcd1, 2 etc for each node
ETCD_DATA_DIR="/var/lib/etcd/default.etcd"  --> leave this as default.etcd --> dont use etcd1 etcd2...
ETCD_LISTEN_CLIENT_URLS="http://192.168.2.101:2379,http://localhost:2379"

[cluster]
ETCD_INITIAL_ADVERTISE_PEER_URLS="http://192.168.2.101:2380"
ETCD_INITIAL_CLUSTER="etcd1=http://192.168.2.101:2380,etcd2=http://192.168.2.102:2380"
ETCD_INITIAL_CLUSTER_STATE="new"
ETCD_ADVERTISE_CLIENT_URLS="http://192.168.2.101:2379"

NODE2:
- /etc/etcd/etcd.conf
[member]
ETCD_NAME=etcd2 --> etcd1, 2 etc for each node
ETCD_DATA_DIR="/var/lib/etcd/default.etcd"  --> leave this as default.etcd --> dont use etcd1 etcd2...
ETCD_LISTEN_CLIENT_URLS="http://192.168.2.102:2379,http://localhost:2379"

[cluster]
ETCD_INITIAL_ADVERTISE_PEER_URLS="http://192.168.2.102:2380"
ETCD_INITIAL_CLUSTER="etcd1=http://192.168.2.101:2380,etcd2=http://192.168.2.102:2380"
ETCD_INITIAL_CLUSTER_STATE="new"
ETCD_ADVERTISE_CLIENT_URLS="http://192.168.2.102:2379"

- START etcd
NOTE: If multinode, do one node at a time

If in doubt, remove database first: (on each node if multi node) (http://www.alexlinux.com/etcd-installation-on-centos-7/)
# rm -rf /var/lib/etcd/*

# systemctl enable etcd
# service etcd start
# netstat -anp |grep etcd
tcp        0      0 127.0.0.1:2380          0.0.0.0:*               LISTEN      4801/etcd           
tcp        0      0 127.0.0.1:7001          0.0.0.0:*               LISTEN      4801/etcd           
tcp        0      0 127.0.0.1:4001          0.0.0.0:*               LISTEN      4801/etcd           
unix  3      [ ]         STREAM     CONNECTED     34387    4801/etcd  

- VERIFY SINGLE NODE
# etcdctl member list
cee1eefbc6bf48c2: name=etcd1 peerURLs=http://192.168.2.101:2380 clientURLs=http://localhost:2379

- VERIFY MULTI NODE
# etcdctl member list
ae525a9a84ebce92: name=etcd2 peerURLs=http://192.168.2.102:2380 clientURLs=http://192.168.2.102:2379
cee1eefbc6bf48c2: name=etcd1 peerURLs=http://192.168.2.101:2380 clientURLs=http://192.168.2.101:2379

--------------------------------
TEST WITH SOME KEYS
--------------------------------
Do this on any etcd node.

[root@ke1 etcd]# etcdctl mkdir /test1/keys
[root@ke1 etcd]# etcdctl ls /
/test1
[root@ke1 etcd]# etcdctl ls /test1
/test1/keys

[root@ke2 ~]# etcdctl mk /test1/keys/key1 "{ \"Network\": \"172.30.0.0/16\", \"SubnetLen\": 24, \"Backend\": { \"Type\": \"vxlan\" } }"

--> Screen output:
{ "Network": "172.30.0.0/16", "SubnetLen": 24, "Backend": { "Type": "vxlan" } }

[root@ke2 ~]# etcdctl get /test1/keys/key1 
{ "Network": "172.30.0.0/16", "SubnetLen": 24, "Backend": { "Type": "vxlan" } }

-------------------------------------
CONFIG CHANGE, CLEANUP, REINSTALL ETC
-------------------------------------
http://www.alexlinux.com/etcd-installation-on-centos-7/

- CHANGE CONF AFTER FIRST START
sed -i s'/ETCD_INITIAL_CLUSTER_STATE="new"/ETCD_INITIAL_CLUSTER_STATE="existing"/'g /etc/etcd/etcd.conf
etcd: already initialized as member before, starting as etcd member

- CLEAN DATA

# rm -rf /var/lib/etcd/*
# systemctl restart etcd
# systemctl status -l etcd

- REINSTALL NODE STEPS
# REMOVE NODE FROM WORKING SERVER
etcdctl member remove xxx
 
# ON NEW NODE
# 0) install etcd
# 1) insert old config
# 2) set ETCD_INITIAL_CLUSTER_STATE="new" in etcd.conf
# 3) start etcd
# 4) add member from working node
# 5) stop etcd
# 6) rm -rf /var/lib/etcd/*
# 7) set ETCD_INITIAL_CLUSTER_STATE="existing" in etcd.conf
# 8) start etcd


===========================================================
KUBERNETES INSTALL ON MASTER
===========================================================
# yum install kubernetes
...
...
Installing:
 kubernetes                 x86_64          1.1.0-0.4.git2bfa9a1.el7          virt7-docker-common-release           26 k
Installing for dependencies:
 docker                     x86_64          1.6.2-4.gitc3ca5bb.el7            virt7-docker-common-release          5.0 M
 kubernetes-client          x86_64          1.1.0-0.4.git2bfa9a1.el7          virt7-docker-common-release          3.0 M
 kubernetes-master          x86_64          1.1.0-0.4.git2bfa9a1.el7          virt7-docker-common-release           14 M
 kubernetes-node            x86_64          1.1.0-0.4.git2bfa9a1.el7          virt7-docker-common-release          9.8 M
 socat                      x86_64          1.7.3.2-2.el7                     ol7_latest                           289 k

Transaction Summary
=========================================================================================================================
Install  1 Package (+5 Dependent packages)

Total download size: 33 M
Installed size: 154 M

- NOW, TAKE A BACKUP OF THIS VM FOR CLONING TO NODES

- CONFIGURE /etc/kubernetes/apiserver file

# The address on the local server to listen to.
#KUBE_API_ADDRESS="--insecure-bind-address=127.0.0.1"
KUBE_API_ADDRESS="--insecure-bind-address=0.0.0.0"

# The port on the local server to listen on.
KUBE_API_PORT="--port=8080"

# Port minions listen on
KUBELET_PORT="--kubelet-port=10250"

# Comma separated list of nodes in the etcd cluster
KUBE_ETCD_SERVERS="--etcd-servers=http://192.168.2.101:2379"

# Address range to use for services
KUBE_SERVICE_ADDRESSES="--service-cluster-ip-range=10.254.0.0/16"

# default admission control policies
KUBE_ADMISSION_CONTROL="--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ServiceAccount,ResourceQuota"

# Add your own!
KUBE_API_ARGS=""

- ENABLE SERVICES

$ for SERVICES in etcd kube-apiserver kube-controller-manager kube-scheduler; do
    systemctl restart $SERVICES
    systemctl enable $SERVICES
    systemctl status $SERVICES 
done
